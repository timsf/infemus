{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "from functools import reduce\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.integrate import quad_vec\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import norm\n",
    "\n",
    "from infemus import emus\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "seed = 0\n",
    "\n",
    "y = 1\n",
    "q = 2 ** 5\n",
    "tau = 2 ** 5\n",
    "\n",
    "n_windows0 = 8\n",
    "n_interp = 32\n",
    "n_iter = 8\n",
    "n_variates = 32\n",
    "n_samples = 8\n",
    "bds = (-6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadrature\n",
    "\n",
    "def eval_logmargin(lam, y, q, tau):\n",
    "    marg_var = 1/q + 1/tau\n",
    "    log_u = np.logaddexp(norm.logpdf(y, loc=lam, scale=np.sqrt(marg_var)), norm.logpdf(-y, loc=lam, scale=np.sqrt(marg_var)))\n",
    "    return log_u\n",
    "\n",
    "def quad_weights(lame, y, q, tau):\n",
    "    prior_prec = tau\n",
    "    post_prec = q + tau\n",
    "    marg_var = 1/q + 1/tau\n",
    "    f = eval_f(lame, y, prior_prec, post_prec, marg_var)\n",
    "    xi = eval_xi(f, lame, y, prior_prec, post_prec, marg_var)\n",
    "    u_quad, _, f_inv = emus.solve_emus_system(f, np.ones_like(f[0]), 100)\n",
    "    score = np.array([np.trace(u_quad[i] ** 2 * f_inv.T @ xi[i] @ f_inv) for i in range(len(xi))])\n",
    "    trunc_score = np.sqrt(np.where(score >= 0, score, 0))\n",
    "    w_quad = trunc_score / np.sum(trunc_score)\n",
    "    return u_quad, w_quad\n",
    "\n",
    "def eval_f(lam, y, prior_prec, post_prec, marg_var):\n",
    "    return np.array([eval_1mom(lam_, lam, y, prior_prec, post_prec, marg_var) for lam_ in lam])\n",
    "\n",
    "def eval_xi(f, lam, y, prior_prec, post_prec, marg_var):\n",
    "    return [eval_2mom(lam[i], lam, y, prior_prec, post_prec, marg_var) - np.outer(f_, f_) for i, f_ in enumerate(f)]\n",
    "\n",
    "def eval_1mom(lam_, lam, y, prior_prec, post_prec, marg_var):\n",
    "    def f(the):\n",
    "        return eval_dens(the, lam_, p_, y, prior_prec, post_prec) * eval_integ(the, lam, prior_prec)\n",
    "    p_ = np.exp(norm.logpdf(y, loc=lam_, scale=np.sqrt(marg_var)) - np.logaddexp(norm.logpdf(y, loc=lam_, scale=np.sqrt(marg_var)), norm.logpdf(-y, loc=lam_, scale=np.sqrt(marg_var))))\n",
    "    return quad_vec(f, -np.inf, np.inf)[0]\n",
    "\n",
    "def eval_2mom(lam_, lam, y, prior_prec, post_prec, marg_var):\n",
    "    def f(the):\n",
    "        phi = eval_integ(the, lam, prior_prec)\n",
    "        return eval_dens(the, lam_, p_, y, prior_prec, post_prec) * np.outer(phi, phi).flatten()\n",
    "    p_ = np.exp(norm.logpdf(y, loc=lam_, scale=np.sqrt(marg_var)) - np.logaddexp(norm.logpdf(y, loc=lam_, scale=np.sqrt(marg_var)), norm.logpdf(-y, loc=lam_, scale=np.sqrt(marg_var))))\n",
    "    return np.reshape(quad_vec(f, -np.inf, np.inf)[0], (len(lam), len(lam)))\n",
    "\n",
    "def eval_dens(the, lam_, p_, y, prior_prec, post_prec):\n",
    "    return p_ * norm.pdf(the, loc=(q*y + lam_*prior_prec)/post_prec, scale=np.sqrt(1/post_prec)) + (1-p_) * norm.pdf(the, loc=(-q*y + lam_*prior_prec)/post_prec, scale=np.sqrt(1/post_prec))\n",
    "\n",
    "def eval_integ(the, lam, prior_prec):\n",
    "    log_psi = norm.logpdf(the, loc=lam, scale=np.sqrt(1/prior_prec))\n",
    "    return np.exp(log_psi - logsumexp(log_psi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "\n",
    "def eval_logmargin(lam, y, q, tau):\n",
    "    marg_var = 1/q + 1/tau\n",
    "    log_u = np.logaddexp(norm.logpdf(y, loc=lam, scale=np.sqrt(marg_var)), norm.logpdf(-y, loc=lam, scale=np.sqrt(marg_var)))\n",
    "    return log_u\n",
    "\n",
    "def resample(lams, lame, y, q, tau, n_samples, ome):\n",
    "    prior_prec = tau\n",
    "    post_prec = q + prior_prec\n",
    "    marg_var = 1/q + 1/tau\n",
    "    p = [np.exp(norm.logpdf(y, loc=lam_, scale=np.sqrt(marg_var)) - np.logaddexp(norm.logpdf(y, loc=lam_, scale=np.sqrt(marg_var)), norm.logpdf(-y, loc=lam_, scale=np.sqrt(marg_var)))) for lam_ in lams]\n",
    "    the_samples = [norm.rvs(loc=(ome.choice([-1, 1], p=[1-p_, p_], size=n_samples)*q*y + lam_*prior_prec)/post_prec, scale=np.sqrt(1/post_prec), random_state=ome) for p_, lam_ in zip(p, lams)]\n",
    "    log_psi = [norm.logpdf(the_[:, np.newaxis], loc=lame[np.newaxis], scale=np.sqrt(1/prior_prec)) for the_ in the_samples]\n",
    "    return log_psi\n",
    "\n",
    "def acquire_windows(n_new, f, ome):\n",
    "    weights = f / np.sum(f)\n",
    "    return subsample_pivotal(weights, n_new, ome)\n",
    "\n",
    "def subsample_stratified(p, n, ome):\n",
    "    u = [ome.uniform(i/n, (i+1)/n) for i in range(n)]\n",
    "    return np.searchsorted(np.cumsum(p), u)\n",
    "\n",
    "def subsample_pivotal(p, n, ome):\n",
    "    t = np.arange(len(p))\n",
    "    s = []\n",
    "    r = []\n",
    "    q = np.copy(p) * n\n",
    "    t = t[p > 0]\n",
    "    q = q[p > 0]\n",
    "    while len(q) > 1:\n",
    "        for i in range(0, len(q), 2):\n",
    "            if i + 1 == len(q):\n",
    "                s.append(i)\n",
    "                break\n",
    "            if q[i] + q[i+1] <= 1:\n",
    "                if ome.uniform() <= q[i] / (q[i] + q[i+1]):\n",
    "                    q[i] += q[i+1]\n",
    "                    q[i+1] = 0\n",
    "                    s.append(i)\n",
    "                else:\n",
    "                    q[i+1] += q[i]\n",
    "                    q[i] = 0\n",
    "                    s.append(i+1)\n",
    "            else:\n",
    "                if ome.uniform() <= (1 - q[i]) / (2 - q[i] - q[i+1]):\n",
    "                    q[i] = q[i] + q[i+1] - 1\n",
    "                    q[i+1] = 1\n",
    "                    s.append(i)\n",
    "                    r.append(t[i+1])\n",
    "                else:\n",
    "                    q[i+1] = q[i] + q[i+1] - 1\n",
    "                    q[i] = 1\n",
    "                    s.append(i+1)\n",
    "                    r.append(t[i])\n",
    "        q = q[s]\n",
    "        t = t[s]\n",
    "        s = []\n",
    "    return np.union1d(r, t)\n",
    "\n",
    "def eval_weights(log_psi):\n",
    "    is_sampled = [(log_psi_.shape[0] > 0) for log_psi_ in log_psi]\n",
    "    log_psis = [log_psi_[:, is_sampled] for log_psi_ in log_psi if log_psi_.shape[0] > 0]\n",
    "    log_psie = [log_psi_ for log_psi_ in log_psi if log_psi_.shape[0] > 0]\n",
    "    log_kaps = [log_psi_ - logsumexp(log_psi_[:, is_sampled], 1)[:, np.newaxis] for log_psi_ in log_psie]\n",
    "    log_kape = [log_psi_ - logsumexp(log_psi_, 1)[:, np.newaxis] for log_psi_ in log_psie]\n",
    "    us = emus.eval_vardi_estimator(log_psis)[0]\n",
    "    log_phi1 = (logsumexp(log_phi_s_[:, :, np.newaxis] + log_phi_e_[:, np.newaxis, :], 0) - np.log(log_phi_s_.shape[0]) + np.log(z_) for z_, log_phi_s_, log_phi_e_ in zip(us, log_kaps, log_kape))\n",
    "    log_f_fill = reduce(np.logaddexp, log_phi1)\n",
    "    f_fill = np.exp(log_f_fill - logsumexp(log_f_fill, 1)[:,np.newaxis])\n",
    "    log_phi2 = (logsumexp(log_phi_s_[:, :, np.newaxis, np.newaxis] + log_phi_e1_[:, np.newaxis, :, np.newaxis] + log_phi_e2_[:, np.newaxis, np.newaxis, :], 0) - np.log(log_phi_s_.shape[0]) + np.log(z_) for z_, log_phi_s_, log_phi_e1_, log_phi_e2_ in zip(us, log_kaps, log_kape, log_kape))\n",
    "    log_f2_fill = reduce(np.logaddexp, log_phi2)\n",
    "    f2_fill = np.exp(log_f2_fill - logsumexp(log_f2_fill, (1, 2))[:,np.newaxis,np.newaxis])\n",
    "    xi = [f2_filled_ - np.outer(f_filled_, f_filled_) for f2_filled_, f_filled_ in zip(f2_fill, f_fill)]\n",
    "    f_filled_inv = emus.solve_emus_system(f_fill, np.ones(len(log_psi)), 100)[2]\n",
    "    ue = emus.extrapolate(log_psie, log_psis, us)\n",
    "    score = np.array([np.trace(ue[i] ** 2 * f_filled_inv.T @ xi[i] @ f_filled_inv) for i in range(len(xi))])\n",
    "    trunc_score = np.sqrt(np.where(score >= 0, score, 0))\n",
    "    we = trunc_score / np.sum(trunc_score)\n",
    "    return ue, we\n",
    "\n",
    "def adjust_weights(n_old, n_new, w_new):\n",
    "    score = (n_new + sum(n_old)) * w_new - n_old\n",
    "    trunc_score = np.where(score > 0, score, 0)\n",
    "    return trunc_score / np.sum(trunc_score)\n",
    "\n",
    "def est_emus_iter(ixn0, lame, y, q, tau, n_samples, ome):\n",
    "    log_psi = [np.empty(shape=(0, len(lame))) for _ in lame]\n",
    "    ixn = ixn0\n",
    "    while True:\n",
    "        log_psi_new = resample(lame[ixn], lame, y, q, tau, n_samples, ome)\n",
    "        for i, ixn_ in enumerate(ixn):\n",
    "            log_psi[ixn_] = np.append(log_psi[ixn_], log_psi_new[i], axis=0)\n",
    "        u, w = eval_weights(log_psi)\n",
    "        w_smooth = np.sqrt(w) / np.sum(np.sqrt(w))\n",
    "        w_adj = adjust_weights(np.array([log_psi_.shape[0] for log_psi_ in log_psi]), n_samples, w_smooth)\n",
    "        ixn = acquire_windows(len(ixn0), w_adj, ome)\n",
    "        yield u, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate ground truth\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "lam = np.linspace(*bds, n_windows0 * n_interp + 1)\n",
    "u_quad, w_quad = quad_weights(lam, y, q, tau)\n",
    "\n",
    "log_u = eval_logmargin(lam, y, q, tau)\n",
    "u = np.exp(np.array(log_u) - logsumexp(log_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw sampling intervals for both methods [fig 10a]\n",
    "\n",
    "ixsfix = np.arange(len(lam))[::n_interp]\n",
    "u_est_flex, w_est_flex = zip(*[next(islice(est_emus_iter(ixsfix, lam, y, q, tau, n_samples, rng), n_iter - 1, n_iter)) for _ in range(n_variates)])\n",
    "u_est_fix, _ = zip(*[next(islice(est_emus_iter(ixsfix, lam, y, q, tau, n_samples * n_iter, rng), 0, 1)) for _ in range(n_variates)])\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(lam, u, color='black')\n",
    "plt.fill_between(lam, *np.percentile(np.vstack([u_est_flex, np.array(u_est_flex)[:,::-1]]), [12.5, 87.5], 0), alpha=.5)\n",
    "plt.fill_between(lam, *np.percentile(np.vstack([u_est_fix, np.array(u_est_fix)[:,::-1]]), [12.5, 87.5], 0), alpha=.5)\n",
    "plt.xlim([-3, 3])\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.ylabel(r'$u(\\lambda)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw optimal intensity function [fig 10b]\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(lam, w_quad, color='black')\n",
    "plt.fill_between(lam, *np.percentile(np.vstack([w_est_flex, np.array(w_est_flex)[:,::-1]]), [12.5, 87.5], 0), alpha=.5)\n",
    "plt.xlim([-3, 3])\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.ylabel(r'$w(\\lambda)$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infemus-paper-o_hx9urg-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
